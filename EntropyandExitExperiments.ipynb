{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"pkoax91_8-mm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrUOWMgwdO8_","executionInfo":{"status":"ok","timestamp":1745799955307,"user_tz":240,"elapsed":38964,"user":{"displayName":"irene paul","userId":"03166737365510433234"}},"outputId":"3e163822-f8d9-41fe-dcde-2044a7ddc231"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1qHoaQqsa_84wKp4XFuiBiBUnxjcdMWJm/CS7643 Deep Learning Project/RelTR\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","import numpy as np\n","import random\n","import time\n","\n","from PIL import Image\n","import requests\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/MyDrive/DeepLearning/CS7643 Deep Learning Project/RelTR\"\n","%load_ext autoreload\n","%autoreload 2\n","from models.backbone import Backbone, Joiner\n","from models.position_encoding import PositionEmbeddingSine\n","from models.transformer import Transformer\n","from models.reltr import RelTR\n","\n","from lib.evaluation.sg_eval import BasicSceneGraphEvaluator\n","import torch\n","import torch.nn.functional as F\n","from torchvision.ops import box_iou\n","from collections import defaultdict\n","import numpy as np\n","from models.matcher import build_matcher\n","from deecap_for_metrics import DeecapRelTR\n","\n","CLASSES = [ 'N/A', 'airplane', 'animal', 'arm', 'bag', 'banana', 'basket', 'beach', 'bear', 'bed', 'bench', 'bike',\n","                'bird', 'board', 'boat', 'book', 'boot', 'bottle', 'bowl', 'box', 'boy', 'branch', 'building',\n","                'bus', 'cabinet', 'cap', 'car', 'cat', 'chair', 'child', 'clock', 'coat', 'counter', 'cow', 'cup',\n","                'curtain', 'desk', 'dog', 'door', 'drawer', 'ear', 'elephant', 'engine', 'eye', 'face', 'fence',\n","                'finger', 'flag', 'flower', 'food', 'fork', 'fruit', 'giraffe', 'girl', 'glass', 'glove', 'guy',\n","                'hair', 'hand', 'handle', 'hat', 'head', 'helmet', 'hill', 'horse', 'house', 'jacket', 'jean',\n","                'kid', 'kite', 'lady', 'lamp', 'laptop', 'leaf', 'leg', 'letter', 'light', 'logo', 'man', 'men',\n","                'motorcycle', 'mountain', 'mouth', 'neck', 'nose', 'number', 'orange', 'pant', 'paper', 'paw',\n","                'people', 'person', 'phone', 'pillow', 'pizza', 'plane', 'plant', 'plate', 'player', 'pole', 'post',\n","                'pot', 'racket', 'railing', 'rock', 'roof', 'room', 'screen', 'seat', 'sheep', 'shelf', 'shirt',\n","                'shoe', 'short', 'sidewalk', 'sign', 'sink', 'skateboard', 'ski', 'skier', 'sneaker', 'snow',\n","                'sock', 'stand', 'street', 'surfboard', 'table', 'tail', 'tie', 'tile', 'tire', 'toilet', 'towel',\n","                'tower', 'track', 'train', 'tree', 'truck', 'trunk', 'umbrella', 'vase', 'vegetable', 'vehicle',\n","                'wave', 'wheel', 'window', 'windshield', 'wing', 'wire', 'woman', 'zebra']\n","\n","REL_CLASSES = ['__background__', 'above', 'across', 'against', 'along', 'and', 'at', 'attached to', 'behind',\n","                'belonging to', 'between', 'carrying', 'covered in', 'covering', 'eating', 'flying in', 'for',\n","                'from', 'growing on', 'hanging from', 'has', 'holding', 'in', 'in front of', 'laying on',\n","                'looking at', 'lying on', 'made of', 'mounted on', 'near', 'of', 'on', 'on back of', 'over',\n","                'painted on', 'parked on', 'part of', 'playing', 'riding', 'says', 'sitting on', 'standing on',\n","                'to', 'under', 'using', 'walking in', 'walking on', 'watching', 'wearing', 'wears', 'with']\n","\n","from types import SimpleNamespace\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","args = {\n","    'bbox_loss_coef': 5,\n","    'giou_loss_coef': 2,\n","    'rel_loss_coef': 1,\n","    'aux_loss': False,\n","    'set_cost_class': 1,\n","    'set_cost_bbox': 5,\n","    'set_cost_giou': 2,\n","    'set_iou_threshold':0.7,\n","    'dataset': 'vg',\n","    'device': device,\n","    'eos_coef': 0.1,\n","    'seed': 42,\n","    'lr_backbone': 1e-5,\n","    'lr': 1e-4,\n","    'lr_drop': 200,\n","    'weight_decay': 1e-4,\n","    'ann_path': 'data/vg/',\n","    'img_folder': 'data/vg/images',\n","    'eval': True,\n","    'batch_size': 10,\n","    'epochs': 10,\n","    'num_workers': 2\n","}\n","args = SimpleNamespace(**args)\n","\n","from models.backbone import build_backbone\n","from models.matcher import build_matcher\n","from models.transformer import build_transformer\n","from models.reltr import SetCriterion, PostProcess\n","from datasets import build_dataset\n","import util.misc as utils\n","from torch.utils.data import DataLoader, DistributedSampler\n","import datasets\n","import util.misc as utils\n","from datasets import build_dataset, get_coco_api_from_dataset\n","from datetime import datetime\n","from engine import evaluate_rel_batch\n","from collections import Counter"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"aIbKjMVS9BBq"}},{"cell_type":"code","source":["def build_model_for_eval(args):\n","  num_classes = 151 if args.dataset != 'oi' else 289 # some entity categories in OIV6 are deactivated.\n","  num_rel_classes = 51 if args.dataset != 'oi' else 31\n","\n","  device = torch.device(args.device)\n","\n","  matcher = build_matcher(args)\n","\n","  model = DeecapRelTR(reltr_model)\n","  model.load_state_dict(torch.load('model weights/avg_mix_50_0.7.pth', map_location=torch.device('cuda')))\n","\n","  model.to(device)\n","\n","  weight_dict = {'loss_ce': 1, 'loss_bbox': args.bbox_loss_coef}\n","  weight_dict['loss_giou'] = args.giou_loss_coef\n","  weight_dict['loss_rel'] = args.rel_loss_coef\n","\n","  # TODO this is a hack\n","  if args.aux_loss:\n","      aux_weight_dict = {}\n","      for i in range(args.dec_layers - 1):\n","          aux_weight_dict.update({k + f'_{i}': v for k, v in weight_dict.items()})\n","      weight_dict.update(aux_weight_dict)\n","\n","  losses = ['labels', 'boxes', 'cardinality', \"relations\"]\n","\n","  criterion = SetCriterion(num_classes, num_rel_classes, matcher=matcher, weight_dict=weight_dict,\n","                            eos_coef=args.eos_coef, losses=losses)\n","  criterion.to(device)\n","  postprocessors = {'bbox': PostProcess()}\n","  return model, criterion, postprocessors\n","\n","position_embedding = PositionEmbeddingSine(128, normalize=True)\n","backbone = Backbone('resnet50', False, False, False)\n","backbone = Joiner(backbone, position_embedding)\n","backbone.num_channels = 2048\n","\n","transformer = Transformer(d_model=256, dropout=0.1, nhead=8,\n","                          dim_feedforward=2048,\n","                          num_encoder_layers=6,\n","                          num_decoder_layers=6,\n","                          normalize_before=False,\n","                          return_intermediate_dec=True)\n","\n","reltr_model = RelTR(backbone, transformer, num_classes=151, num_rel_classes = 51,\n","              num_entities=100, num_triplets=200)\n","\n","# The checkpoint is pretrained on Visual Genome\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","ckpt = torch.load('ckpt/checkpoint0149.pth', map_location=torch.device(device), weights_only=False)\n","reltr_model.load_state_dict(ckpt['model'])\n","reltr_model.eval()\n","for param in reltr_model.parameters():\n","    param.requires_grad = False\n","\n","utils.init_distributed_mode(args)\n","\n","device = torch.device(args.device)\n","\n","# fix the seed for reproducibility\n","seed = args.seed + utils.get_rank()\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","\n","model, criterion, postprocessors = build_model_for_eval(args)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FA4B-SeEdaSy","executionInfo":{"status":"ok","timestamp":1745799979603,"user_tz":240,"elapsed":15025,"user":{"displayName":"irene paul","userId":"03166737365510433234"}},"outputId":"db1f0fe9-448b-43fe-9441-860d37823729"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Not using distributed mode\n","loading annotations into memory...\n","Done (t=0.75s)\n","creating index...\n","index created!\n"]}]},{"cell_type":"markdown","source":["# Load Dataset"],"metadata":{"id":"7WMBQnTJ9J1K"}},{"cell_type":"code","source":["dataset_test = build_dataset(image_set='val', args=args)\n","\n","sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n","\n","# small_indices = list(range(20))  # <-- 20 = no of samples to test.\n","# sampler_test = torch.utils.data.SubsetRandomSampler(small_indices)\n","\n","data_loader_test = DataLoader(dataset_test, args.batch_size, sampler=sampler_test,\n","                             drop_last=False, collate_fn=utils.collate_fn, num_workers=args.num_workers)\n","\n","base_ds = get_coco_api_from_dataset(dataset_test)"],"metadata":{"id":"yUTx13N0uW2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()  # modification of engine.py in https://github.com/yrcong/RelTR\n","def evaluate(model, criterion, postprocessors, data_loader, base_ds, device, args, imitate=True):\n","    model.eval()\n","    criterion.eval()\n","\n","    if hasattr(args, 'exit'):\n","      print(\"Evaluation for exit at layer-\", args.exit)\n","\n","\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('class_error', utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))\n","    metric_logger.add_meter('sub_error', utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))\n","    metric_logger.add_meter('obj_error', utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))\n","    metric_logger.add_meter('rel_error', utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))\n","    header = 'Test:'\n","\n","    # initilize evaluator\n","    if args.dataset == 'vg':\n","        evaluator = BasicSceneGraphEvaluator.all_modes(multiple_preds=False)\n","        if args.eval:\n","            evaluator_list = []\n","            for index, name in enumerate(data_loader.dataset.rel_categories):\n","                if index == 0:\n","                    continue\n","                evaluator_list.append((index, name, BasicSceneGraphEvaluator.all_modes()))\n","        else:\n","            evaluator_list = None\n","    else:\n","        all_results = []\n","\n","    iou_types = tuple(k for k in ('segm', 'bbox') if k in postprocessors.keys())\n","    coco_evaluator = CocoEvaluator(base_ds, iou_types)\n","    all_exit_layers = []\n","    avg_entropy = 0\n","    for samples, targets in metric_logger.log_every(data_loader, 100, header):\n","\n","        samples = samples.to(device)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        outputs = None\n","        if hasattr(args, 'exit'):\n","          outputs, entropy, batch_exit_layers = model(samples, layer_exit = args.exit, imitate=imitate)\n","        else:\n","          if hasattr(args, 'confidence_threshold'):\n","            outputs, entropy, batch_exit_layers = model(samples, confidence_threshold = args.confidence_threshold, imitate=imitate)\n","            avg_entropy += entropy\n","          else:\n","            outputs, entropy, batch_exit_layers = model(samples)\n","            avg_entropy += entropy\n","          avg_entropy /= 2\n","        all_exit_layers.extend(batch_exit_layers)\n","        loss_dict = criterion(outputs, targets)\n","        weight_dict = criterion.weight_dict\n","\n","        # reduce losses over all GPUs for logging purposes\n","        loss_dict_reduced = utils.reduce_dict(loss_dict)\n","        loss_dict_reduced_scaled = {k: v * weight_dict[k]\n","                                    for k, v in loss_dict_reduced.items() if k in weight_dict}\n","        loss_dict_reduced_unscaled = {f'{k}_unscaled': v\n","                                      for k, v in loss_dict_reduced.items()}\n","        metric_logger.update(loss=sum(loss_dict_reduced_scaled.values()),\n","                             **loss_dict_reduced_scaled,\n","                             **loss_dict_reduced_unscaled)\n","        metric_logger.update(class_error=loss_dict_reduced['class_error'])\n","        metric_logger.update(sub_error=loss_dict_reduced['sub_error'])\n","        metric_logger.update(obj_error=loss_dict_reduced['obj_error'])\n","        metric_logger.update(rel_error=loss_dict_reduced['rel_error'])\n","\n","        if args.dataset == 'vg':\n","            evaluate_rel_batch(outputs, targets, evaluator, evaluator_list)\n","        else:\n","            evaluate_rel_batch_oi(outputs, targets, all_results)\n","\n","        orig_target_sizes = torch.stack([t[\"orig_size\"] for t in targets], dim=0)\n","        results = postprocessors['bbox'](outputs, orig_target_sizes)\n","\n","        res = {target['image_id'].item(): output for target, output in zip(targets, results)}\n","        if coco_evaluator is not None:\n","            coco_evaluator.update(res)\n","\n","    if args.dataset == 'vg':\n","        evaluator['sgdet'].print_stats()\n","        # evaluator['sgcls'].print_stats()\n","        # evaluator['predcls'].print_stats()\n","    else:\n","        task_evaluation_sg.eval_rel_results(all_results, 100, do_val=True, do_vis=False)\n","\n","    if args.eval and args.dataset == 'vg':\n","        calculate_mR_from_evaluator_list(evaluator_list, 'sgdet')\n","        calculate_mR_from_evaluator_list(evaluator_list, 'sgcls')\n","        calculate_mR_from_evaluator_list(evaluator_list, 'predcls')\n","\n","    # gather the stats from all processes\n","    metric_logger.synchronize_between_processes()\n","    print(\"Averaged stats:\", metric_logger)\n","    if coco_evaluator is not None:\n","        coco_evaluator.synchronize_between_processes()\n","\n","    # accumulate predictions from all images\n","    if coco_evaluator is not None:\n","        coco_evaluator.accumulate()\n","        coco_evaluator.summarize()\n","\n","    stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n","    if coco_evaluator is not None:\n","        if 'bbox' in postprocessors.keys():\n","            stats['coco_eval_bbox'] = coco_evaluator.coco_eval['bbox'].stats.tolist()\n","\n","    return stats, coco_evaluator, avg_entropy, all_exit_layers"],"metadata":{"id":"Kg6pp1n0-R7g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate Average Entropy Values Per Layer + Time Taken for inference per Layer"],"metadata":{"id":"ffk4vUwx9Rq5"}},{"cell_type":"code","source":["import time\n","import matplotlib.pyplot as plt\n","args['exit'] = 0\n","del args['confidence_threshold']\n","times, avg_entropies = [], []\n","layers = [0, 1, 2, 3, 4, 5]\n","\n","for layer in layers:\n","    if args.eval:\n","        args.exit = layer\n","        print(f\"Entropy Level: {layer}\")\n","        start = time.time()\n","        test_stats, coco_evaluator, avg_entropy, all_exit_layers = evaluate(\n","            model, criterion, postprocessors, data_loader_test, base_ds, device, args\n","        )\n","        times.append(time.time() - start)\n","        avg_entropies.append(avg_entropy)\n","\n","plt.plot(layers, times, marker='o')\n","plt.xlabel('Layer'); plt.ylabel('Time (s)')\n","plt.title('Inference Time vs Exit Layer')\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","plt.plot(layers, avg_entropies, marker='o', color='orange')\n","plt.xlabel('Layer'); plt.ylabel('Average Entropy')\n","plt.title('Average Entropy vs Exit Layer')\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"KcLGQDcf9VdY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate Exit Layer Distribution over different Entropies"],"metadata":{"id":"UktKcr-j9WDt"}},{"cell_type":"code","source":["import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from collections import Counter\n","args['confidence_threshold'] = 0\n","del args['exit']\n","exit_distributions = {}\n","avg_exit_layers = {}\n","entropies = [0.4, 0.45, 0.5, 0.55, 0.6]\n","\n","for entropy in entropies:\n","    if args.eval:\n","        args.confidence_threshold = entropy\n","        print(f\"Entropy Threshold: {entropy}\")\n","        test_stats, coco_evaluator, avg_entropy, all_exit_layers = evaluate(\n","            model, criterion, postprocessors, data_loader_test, base_ds, device, args\n","        )\n","        counts = Counter(all_exit_layers)\n","        total = sum(counts.values())\n","        exit_distributions[entropy] = {layer: counts.get(layer, 0) / total * 100 for layer in range(6)}\n","        avg_exit_layers[entropy] = sum(layer * count for layer, count in counts.items()) / total\n","\n","layers = list(range(6))\n","x = np.arange(len(entropies))\n","width = 0.5\n","bottom = np.zeros(len(entropies))\n","colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n","\n","fig, ax = plt.subplots(figsize=(7,5))\n","\n","for idx, layer in enumerate(layers):\n","    values = [exit_distributions[e].get(layer, 0) for e in entropies]\n","    ax.bar(x, values, bottom=bottom, width=width, label=f'Layer {layer}', color=colors[idx])\n","    bottom += values\n","\n","ax.set_xlabel('Entropy Threshold')\n","ax.set_ylabel('Percentage of Samples')\n","ax.set_title('Exit Layer Distribution Across Entropy Thresholds')\n","ax.set_xticks(x)\n","ax.set_xticklabels(entropies)\n","ax.legend(title='Exit Layer')\n","ax.grid(True, linestyle='--', alpha=0.5)\n","plt.tight_layout()\n","plt.show()\n","\n","plt.figure(figsize=(6,4))\n","plt.plot(entropies, [avg_exit_layers[e] for e in entropies], marker='o', color='black')\n","plt.xlabel('Entropy Threshold')\n","plt.ylabel('Average Exit Layer')\n","plt.title('Average Exit Layer vs Entropy Threshold')\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"hebznzUY9lOg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate inference time for exit v no exit"],"metadata":{"id":"fhBu3wKc9l23"}},{"cell_type":"code","source":["import time\n","\n","del args['exit']\n","del args['confidence_threshold']\n","\n","for entropy in entropies:\n","    if args.eval:\n","        print(f\"Entropy Threshold: {entropy}\")\n","\n","        args['confidence_threshold'] = 0.6\n","        start = time.time()\n","        test_stats_exit, coco_evaluator_exit, avg_entropy_exit, all_exit_layers_exit = evaluate(\n","            model, criterion, postprocessors, data_loader_test, base_ds, device, args\n","        )\n","        time_exit = time.time() - start\n","        print(f\"Early Exit Inference Time: {time_exit:.2f} seconds\")\n","\n","        args['confidence_threshold'] = 0\n","        start = time.time()\n","        test_stats_full, coco_evaluator_full, avg_entropy_full, all_exit_layers_full = evaluate(\n","            model, criterion, postprocessors, data_loader_test, base_ds, device, args\n","        )\n","        time_full = time.time() - start\n","        print(f\"Full Model Inference Time: {time_full:.2f} seconds\")\n"],"metadata":{"id":"HCqRll3U9pcg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate With and without imitation performance"],"metadata":{"id":"ZbALsxqw9qXp"}},{"cell_type":"code","source":["import time\n","\n","del args['exit']\n","del args['confidence_threshold']\n","\n","for entropy in entropies:\n","    if args.eval:\n","        print(f\"With Imitation: {entropy}\")\n","\n","        args['confidence_threshold'] = 0.6\n","        start = time.time()\n","        test_stats_exit, coco_evaluator_exit, avg_entropy_exit, all_exit_layers_exit = evaluate(\n","            model, criterion, postprocessors, data_loader_test, base_ds, device, args, imitate=True\n","        )\n","        time_exit = time.time() - start\n","        print(f\"Without Imitation: {time_exit:.2f} seconds\")\n","\n","        args['confidence_threshold'] = 0\n","        start = time.time()\n","        test_stats_full, coco_evaluator_full, avg_entropy_full, all_exit_layers_full = evaluate(\n","            model, criterion, postprocessors, data_loader_test, base_ds, device, args, imitate = False\n","        )\n","        time_full = time.time() - start\n","        print(f\"Full Model Inference Time: {time_full:.2f} seconds\")\n"],"metadata":{"id":"T9NAjoOH9u-L"},"execution_count":null,"outputs":[]}]}